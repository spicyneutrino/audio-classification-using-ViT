/scratch/ptolemy/users/kg1623/projects/deep-learning/audio-classification-using-ViT/venv/lib/python3.10/site-packages/torch_audiomentations/core/transforms_interface.py:76: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = Gain(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/scratch/ptolemy/users/kg1623/projects/deep-learning/audio-classification-using-ViT/venv/lib/python3.10/site-packages/torch_audiomentations/core/transforms_interface.py:76: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = AddColoredNoise(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/scratch/ptolemy/users/kg1623/projects/deep-learning/audio-classification-using-ViT/venv/lib/python3.10/site-packages/torch_audiomentations/core/transforms_interface.py:76: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = PitchShift(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
/scratch/ptolemy/users/kg1623/projects/deep-learning/audio-classification-using-ViT/venv/lib/python3.10/site-packages/torch_audiomentations/core/transforms_interface.py:76: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:
  >>> augment = Shift(..., output_type='dict')
  >>> augmented_samples = augment(samples).samples
  warnings.warn(
Using the latest cached version of the dataset since danavery/urbansound8K couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /scratch/ptolemy/users/kg1623/.cache/huggingface/datasets/danavery___urbansound8_k/default/0.0.0/8aa9177a0c5a6949ee4ee4b7fcabb01dfd4ae466 (last modified on Sat Apr 26 19:45:24 2025).
/scratch/ptolemy/users/kg1623/projects/deep-learning/audio-classification-using-ViT/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
  0%|          | 0/70 [00:00<?, ?it/s]  1%|▏         | 1/70 [04:31<5:11:58, 271.29s/it]  3%|▎         | 2/70 [08:57<5:04:19, 268.52s/it]  4%|▍         | 3/70 [13:25<4:59:17, 268.03s/it]  6%|▌         | 4/70 [17:51<4:53:58, 267.25s/it]  7%|▋         | 5/70 [22:18<4:49:21, 267.10s/it]  9%|▊         | 6/70 [26:40<4:43:07, 265.44s/it] 10%|█         | 7/70 [31:03<4:37:59, 264.75s/it] 11%|█▏        | 8/70 [35:32<4:34:56, 266.08s/it] 13%|█▎        | 9/70 [39:59<4:30:42, 266.27s/it] 14%|█▍        | 10/70 [44:29<4:27:27, 267.46s/it] 16%|█▌        | 11/70 [48:51<4:21:22, 265.81s/it] 17%|█▋        | 12/70 [53:22<4:18:20, 267.25s/it] 19%|█▊        | 13/70 [57:44<4:12:34, 265.86s/it] 20%|██        | 14/70 [1:02:13<4:08:59, 266.79s/it] 21%|██▏       | 15/70 [1:06:38<4:04:08, 266.34s/it] 23%|██▎       | 16/70 [1:11:02<3:58:52, 265.42s/it] 24%|██▍       | 17/70 [1:15:27<3:54:17, 265.23s/it] 26%|██▌       | 18/70 [1:19:53<3:50:07, 265.53s/it] 27%|██▋       | 19/70 [1:24:24<3:47:02, 267.10s/it] 29%|██▊       | 20/70 [1:28:48<3:41:50, 266.21s/it] 30%|███       | 21/70 [1:33:18<3:38:31, 267.59s/it] 31%|███▏      | 22/70 [1:37:44<3:33:31, 266.91s/it] 33%|███▎      | 23/70 [1:42:14<3:29:55, 268.00s/it] 34%|███▍      | 24/70 [1:46:41<3:25:05, 267.51s/it] 36%|███▌      | 25/70 [1:51:05<3:19:58, 266.63s/it] 37%|███▋      | 26/70 [1:55:34<3:15:56, 267.19s/it] 39%|███▊      | 27/70 [1:59:59<3:11:00, 266.53s/it] 40%|████      | 28/70 [2:04:30<3:07:28, 267.82s/it] 41%|████▏     | 29/70 [2:08:58<3:03:07, 267.99s/it] 43%|████▎     | 30/70 [2:13:23<2:58:01, 267.03s/it] 44%|████▍     | 31/70 [2:17:52<2:54:01, 267.73s/it] 46%|████▌     | 32/70 [2:22:20<2:49:35, 267.77s/it] 47%|████▋     | 33/70 [2:26:48<2:45:05, 267.72s/it] 49%|████▊     | 34/70 [2:31:17<2:40:54, 268.18s/it] 50%|█████     | 35/70 [2:35:44<2:36:18, 267.96s/it] 51%|█████▏    | 36/70 [2:40:13<2:31:53, 268.04s/it] 53%|█████▎    | 37/70 [2:44:43<2:27:47, 268.70s/it] 54%|█████▍    | 38/70 [2:49:12<2:23:24, 268.88s/it] 56%|█████▌    | 39/70 [2:53:38<2:18:26, 267.94s/it] 57%|█████▋    | 40/70 [2:58:12<2:14:55, 269.85s/it] 59%|█████▊    | 41/70 [3:02:43<2:10:34, 270.17s/it] 60%|██████    | 42/70 [3:07:11<2:05:48, 269.58s/it] 61%|██████▏   | 43/70 [3:11:41<2:01:20, 269.63s/it] 63%|██████▎   | 44/70 [3:16:08<1:56:26, 268.71s/it] 64%|██████▍   | 45/70 [3:20:34<1:51:37, 267.89s/it] 66%|██████▌   | 46/70 [3:25:00<1:47:00, 267.53s/it] 67%|██████▋   | 47/70 [3:29:32<1:43:05, 268.95s/it] 69%|██████▊   | 48/70 [3:33:57<1:38:09, 267.72s/it] 70%|███████   | 49/70 [3:38:24<1:33:32, 267.29s/it] 71%|███████▏  | 50/70 [3:42:58<1:29:46, 269.35s/it] 73%|███████▎  | 51/70 [3:47:33<1:25:52, 271.18s/it] 74%|███████▍  | 52/70 [3:52:02<1:21:08, 270.46s/it] 76%|███████▌  | 53/70 [3:56:36<1:16:56, 271.54s/it] 77%|███████▋  | 54/70 [4:01:08<1:12:25, 271.58s/it] 79%|███████▊  | 55/70 [4:05:43<1:08:09, 272.61s/it] 80%|████████  | 56/70 [4:10:10<1:03:15, 271.09s/it] 81%|████████▏ | 57/70 [4:14:41<58:41, 270.86s/it]   83%|████████▎ | 58/70 [4:19:07<53:52, 269.38s/it] 83%|████████▎ | 58/70 [4:23:36<54:32, 272.70s/it]
/scratch/ptolemy/users/kg1623/projects/deep-learning/audio-classification-using-ViT/venv/lib/python3.10/site-packages/torch/__init__.py:2150: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  assert condition, message
